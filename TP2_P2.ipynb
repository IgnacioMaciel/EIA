{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgnacioMaciel/EIA/blob/main/TP2_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMZqDYYBzCLe"
      },
      "source": [
        "# Programacion Concurrente TP2 Parte2 MPI\n",
        "\n",
        "Para este ejercicio se ha optado por aplicar el tema teórico **MPI** (Message Passing Interface). La finalidad del ejercicio es ampliar el conocimiento sobras la manera que posee Python para implementar la comunicación entre distintos procesos con el uso de una librería denominada **MPI4py** [1]. Para más información puede consultar la última revisión en [2].\n",
        "\n",
        "Este ejercicio fue presentado por alumnos del curso 2020."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 2.1. Ejercicio - Hola Mundo con MPI\n"
      ],
      "metadata": {
        "id": "yE4nz1TozCQO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.1. Preguntas del ejercicio\n",
        "\n",
        "Ejecute este ejemplo para $4$ o más instancias y responda:\n",
        "\n",
        "**a) ¿Qué función realiza la instancia maestra? ¿Qué función realizan las instancias esclavas?**\n",
        "\n",
        "La instancia maestra, con el ID 0, tiene la función de coordinar y controlar el flujo de trabajo. Es responsable de generar las tareas de trabajo, asignarlas a las instancias esclavas, recibir los resultados de las tareas y enviar nuevas tareas a medida que se completan. También es responsable de enviar la señal de finalización cuando todas las tareas se han completado.\n",
        "\n",
        "Las instancias esclavas, con IDs diferentes de 0, tienen la función de realizar el trabajo asignado por la instancia maestra. Reciben las tareas del maestro, realizan el trabajo y envían los resultados.\n",
        "\n",
        "**b) ¿Cuántas de esas instancias ejecuta la función `main()`, `initWork()` y `doWork()`?**\n",
        "\n",
        "La función main() se ejecuta en todas las instancias, tanto en la instancia maestra como en las instancias esclavas. Esta función establece la comunicación entre los procesos y decide si un proceso es el proceso maestro o un proceso esclavo según su identificación (id).\n",
        "\n",
        "Si el proceso es el proceso maestro (identificación id = 0), se llama a la función init() una vez para realizar ciertas inicializaciones y se generan tareas utilizando la función generateTasks(). Luego, se llama a la función initWork() pasando los parámetros necesarios.\n",
        "\n",
        "La función initWork() se ejecuta solo en la instancia maestra. En esta función, se envían las tareas iniciales a los procesos esclavos utilizando la función comm.send(). Después de enviar las tareas iniciales, se inicia un bucle mientras haya trabajo pendiente. En este bucle, el proceso maestro recibe los resultados de los empleados (procesos esclavos) utilizando comm.recv() y envía más trabajo utilizando comm.send(). Al finalizar, se envía una señal de finalización a los procesos esclavos.\n",
        "\n",
        "Si el proceso es un proceso esclavo (identificación id != 0), se ejecuta la función doWork(). Esta función se ejecuta solo en las instancias esclavas. En el bucle de esta función, el proceso esclavo recibe la cantidad de tiempo de descanso del proceso maestro utilizando comm.recv(). Luego, espera durante ese tiempo utilizando time.sleep() y envía el tiempo de descanso nuevamente al proceso maestro utilizando comm.send(). El proceso esclavo continúa este bucle hasta que recibe una señal de finalización.\n",
        "\n",
        "**c) ¿Cómo se diferencian los mensajes de trabajo o de finalización?**\n",
        "\n",
        "Los mensajes de trabajo son enviados por el maestro a las instancias esclavas utilizando el tag WORK_FLAG. Estos mensajes contienen las tareas de trabajo que las instancias esclavas deben realizar.\n",
        "\n",
        "El mensaje de finalización es enviado por el maestro a todas las instancias (tanto maestra como esclavas) utilizando el tag END_WORK_FLAG. Este mensaje indica a las instancias que deben finalizar su trabajo y salir del bucle de trabajo.\n",
        "\n",
        "**d) ¿Cómo implementaría la función BLAS `axpy()` con este patrón?¿Sería eficiente? *Tips*: Pide solo el planteo, no la implementación.**\n",
        "\n",
        "Para implementar la función BLAS axpy() con este patrón, se podrían seguir los siguientes pasos:\n",
        "\n",
        "1.   La instacia maestra genera los datos de entrada, como los vectores x e y y el escalar a.\n",
        "2.   La instancia maestra divide los datos en segmentos y envía cada segmento a las instancias esclavas utilizando comm.send().\n",
        "3.  Cada instancia esclava recibe su segmento de datos utilizando comm.recv().\n",
        "4.  Cada instancia esclava realiza la operación axpy() en su segmento de datos.\n",
        "5.  Cada instancia esclava envía su resultado parcial al maestro utilizando comm.send().\n",
        "6.  La instancia maestra recibe los resultados parciales de las instancias esclavas y los combina para obtener el resultado final.\n",
        "\n",
        "Esta implementación podría ser eficiente si los datos se dividen en segmentos de forma pareja entre las instancias esclavas y si el costo de comunicación entre la instancia maestra y las instancias esclavas no es significativo en comparación con el costo de computación de la operación axpy(). Además, como vimos en el trabajo práctico anterior, la operación axpy() es altamente paralelizable y puede aprovechar los recursos de cada instancia esclava por ende, el rendimiento puede ser bueno.\n",
        "\n",
        "**e) ¿Qué sucede cuando solo ejecuta con una sola instancia?**\n",
        "\n",
        "Cuando solo se ejecuta con una sola instancia, el programa se ejecutará pero no habrá instancias esclavas para realizar el trabajo. En este caso, ninguna instancia realizará las tareas.\n",
        "En cambio, con dos instancias, se creará una instancia esclava que realizará todas las tareas.\n",
        "\n",
        "**f) *Punto opcional*: El código que ejecutan las instancias esclavas, tienen un error en su lógica. ¿Cómo se podría solucionar?**\n",
        "\n",
        "Creemos que el error se encuentra en el uso de MPI.ANY_TAG en el parámetro tag de la función comm.recv(). Esto significa que el proceso esclavo puede recibir cualquier etiqueta de mensaje, lo que incluye la etiqueta END_WORK_FLAG. Como resultado, cuando se recibe la señal de finalización, el proceso esclavo sale del bucle y finaliza su ejecución. Sin embargo, antes de finalizar, se supone que debe enviar el tiempo de descanso nuevamente al proceso maestro.\n",
        "\n",
        "Modificando MPI.ANY_TAG por WORK_FLAG en el parámetro tag de la función comm.recv() garantizaria que el proceso esclavo solo reciba mensajes con la etiqueta WORK_FLAG y no salga del bucle hasta recibir la señal de finalización con la etiqueta END_WORK_FLAG. Además se podria agregar la funcion comm.send() con el tag END_WORK_FLAG antes del return para asegurarnos de que el tiempo de descanso se envíe al proceso maestro."
      ],
      "metadata": {
        "id": "AMFBYImZzLVo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9TdOhH3zGsx"
      },
      "source": [
        "###2.1.2. Armado del ambiente\n",
        "\n",
        "Es en donde se instalar, por única vez, el módulo MPI4py de Python en el cuaderno."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV_cRj3n4SF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee842fa-3e9b-46cc-e2f3-43257331c832"
      },
      "source": [
        "! pip install mpi4py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpi4py\n",
            "  Downloading mpi4py-3.1.4.tar.gz (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: mpi4py\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-3.1.4-cp310-cp310-linux_x86_64.whl size=3365640 sha256=ac0ce64e25efdf6bbccc2a80cfe39dca7973bedc8d07cd1c0da3b1c44541a008\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/1b/b5/97ec4cfccdde26e0f3590ad6e09a5242d508dff09704ef86c1\n",
            "Successfully built mpi4py\n",
            "Installing collected packages: mpi4py\n",
            "Successfully installed mpi4py-3.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1.3. Código del programa en Lenguaje Python"
      ],
      "metadata": {
        "id": "lgqoWIVPzZkY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGvDuYLk4zpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d068caeb-438f-498d-ad59-bc2abc9fe0ed"
      },
      "source": [
        "%%writefile Ejercicio2.py\n",
        "from mpi4py import MPI\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# --------------------------------------------\n",
        "# Formulario\n",
        "Max_tiempo_sleep =   5#@param {type: \"slider\", min: 1, max: 10}\n",
        "Min_tiempo_sleep =   0#@param {type: \"slider\", min: 0, max: 10}\n",
        "# --------------------------------------------\n",
        "\n",
        "# --------------------------------------------\n",
        "# Constantes de comunicacion\n",
        "WORK_FLAG = 1\n",
        "END_WORK_FLAG = 2\n",
        "# --------------------------------------------\n",
        "\n",
        "def main():\n",
        "    comm = MPI.COMM_WORLD # Instanciamos el tipo de comunicador a utilizar.\n",
        "    id = comm.Get_rank()  # Obtenemos el id como atributo del proceso que se ejecuta.\n",
        "\n",
        "    # Utilizamos el 0 para definir al procesos Maestro, cualquier otro id sera un esclavo.\n",
        "    if (id == 0) :\n",
        "        init() # Llamamos funcion init para eventos que requeriremos inicialmente solo 1 vez.\n",
        "        numProcesses = comm.Get_size() # Obtenemos el numero de procesos totales ejecutados.\n",
        "        numTasks = (numProcesses-1)*4 # Se setea el numero de tareas.\n",
        "        workTimes = generateTasks(numTasks) # Se generan las tareas, en este caso seran\n",
        "        print(\"El jefe crea {} horas de descanso de sus empleados:\".format(workTimes.size), flush=True)\n",
        "        print(workTimes, flush=True)\n",
        "        initWork(comm, workTimes, numProcesses)\n",
        "    else:\n",
        "        doWork(comm)\n",
        "\n",
        "def generateTasks(numTasks):\n",
        "    #TODO: Cambiar la semilla del random para que se generen efectivamente diferentes numeros.\n",
        "    np.random.seed(1000)\n",
        "    return np.random.randint(low=Min_tiempo_sleep, high=Max_tiempo_sleep, size=numTasks)\n",
        "\n",
        "def init():\n",
        "  print()\n",
        "  print(\"Version MPI4py utilizada: {}\".format(MPI.Get_version()), flush=True)\n",
        "  print()\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print( \"Sistema de trabajo Suizo:\", flush=True)\n",
        "  print( \"------------------------------------\", flush=True)\n",
        "  print()\n",
        "\n",
        "def initWork(comm, workTimes, numProcesses):\n",
        "    totalWork = workTimes.size\n",
        "    workcount = 0\n",
        "    recvcount = 0\n",
        "\n",
        "    print(\"Jefe enviando las tareas iniciales:\", flush=True)\n",
        "    for id in range(1, numProcesses):\n",
        "        if workcount < totalWork:\n",
        "            work=workTimes[workcount]\n",
        "            comm.send(work, dest=id, tag=WORK_FLAG) # Envia mensaje de iniciar trabajo con el dato correspondiente del array.\n",
        "            workcount += 1\n",
        "            print(\"Jefe envia trabajo y {} hs de descanso al empleado {}.\".format(work, id), flush=True)\n",
        "    print( \"------------------------------------\", flush=True)\n",
        "\n",
        "    # Mientras haya trabajo, se recibe el resultado de los empleados y se sigue enviando MAS trabajo.\n",
        "    while (workcount < totalWork) :\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat) # Recivimos resultados de los empleados.\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source() # Obtenemos el identificador del empleado.\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "        #send next work\n",
        "        work=workTimes[workcount]\n",
        "        comm.send(work, dest=workerId, tag=WORK_FLAG)\n",
        "        workcount += 1\n",
        "        print(\"Jefe envia nuevo trabajo y {} hs de descanso al empleado {}.\".format(work, workerId), flush=True)\n",
        "\n",
        "    while (recvcount < totalWork):\n",
        "        stat = MPI.Status()\n",
        "        workTime = comm.recv(source=MPI.ANY_SOURCE, status=stat)\n",
        "        recvcount += 1\n",
        "        workerId = stat.Get_source()\n",
        "        print(\"Jefe recibe trabajo completado {} del empleado {}.\".format(workTime, workerId), flush=True)\n",
        "\n",
        "    for id in range(1, numProcesses):\n",
        "        comm.send(0, dest=id, tag=END_WORK_FLAG)\n",
        "\n",
        "\n",
        "def doWork(comm):\n",
        "    while(True):\n",
        "        stat = MPI.Status() # Obtiene el estado actual del empleado.\n",
        "        waitTime = comm.recv(source=0, tag=MPI.ANY_TAG, status=stat) # Obtiene lo enviado por el Jefe.\n",
        "        print(\"Soy el empleado con id {}, toca descanzo por {} hs.\".format(comm.Get_rank(), waitTime), flush=True)\n",
        "\n",
        "        if (stat.Get_tag() == END_WORK_FLAG):\n",
        "            print(\"Marca tarjeta el empleado {}.\".format(comm.Get_rank()), flush=True)\n",
        "            return\n",
        "        time.sleep(waitTime)\n",
        "        comm.send(waitTime, dest=0)\n",
        "\n",
        "main()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Ejercicio2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anJw5JH-443-"
      },
      "source": [
        "### 2.1.4 Ejecución del programa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEtBCIa4-LP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e238a7e-574a-45d4-8f4f-d3d8aeb23cf7"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title Parámetros de ejecución { vertical-output: true }\n",
        "NRO =   1#@param {type: \"number\"}\n",
        "# --------------------------------------------\n",
        "\n",
        "! mpirun --allow-run-as-root --oversubscribe -np $NRO python Ejercicio2.py"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Version MPI4py utilizada: (3, 1)\n",
            "\n",
            "------------------------------------\n",
            "Sistema de trabajo Suizo:\n",
            "------------------------------------\n",
            "\n",
            "El jefe crea 0 horas de descanso de sus empleados:\n",
            "[]\n",
            "Jefe enviando las tareas iniciales:\n",
            "------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChP75EDxI89c"
      },
      "source": [
        "---\n",
        "# Bibliografía\n",
        "\n",
        "[1] MPI4py: https://mpi4py.readthedocs.io/en/stable/\n",
        "\n",
        "[2] La versión oficial de MPI (Versión 4): https://www.mpi-forum.org/docs/mpi-4.0/mpi40-report.pdf\n",
        "\n"
      ]
    }
  ]
}